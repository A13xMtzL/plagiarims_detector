{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from preparation import preparation\n",
    "from model import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprime matriz de confusión\n",
    "def print_confussion_matrix(y_test, y_pred):\n",
    "    sns.heatmap((confusion_matrix(y_test,y_pred)), annot=True, fmt=\"d\",cmap=\"crest\")\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True class')\n",
    "    plt.xlabel('Predicted class')\n",
    "    plt.show()\n",
    "\n",
    "def print_roc(fpr, tpr, roc_auc):\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.title('ROC curve')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Se leen todos los documentos y con estos utiliza la función de similitud coseno entre los textos, para asi determinar si hay plagio o no.\n",
    "#Finalmente, muestra todos los histogramas, curva ROC y matriz de confusión.\n",
    "\n",
    "def decision(file_path_originals, file_path_suspicious, actual_results):\n",
    "\n",
    "    system_results = []\n",
    "\n",
    "    # Preproceso de textos originales\n",
    "    original_texts = [file for file in os.listdir(file_path_originals) if os.path.isfile(os.path.join(file_path_originals, file))]\n",
    "    processed_original_texts = []\n",
    "    for original_text in original_texts:\n",
    "        text = preprocessing(file_path_originals + \"/\" + original_text)\n",
    "        processed_original_texts.append(text)\n",
    "\n",
    "\n",
    "    # Preproceso de textos sospechosos\n",
    "    suspicious_texts = [file for file in os.listdir(file_path_suspicious) if os.path.isfile(os.path.join(file_path_suspicious, file))]\n",
    "    processed_suspicious_texts = []\n",
    "    for suspicious_text in suspicious_texts:\n",
    "        text = preprocessing(file_path_suspicious + \"/\" + suspicious_text)\n",
    "        processed_suspicious_texts.append(text)\n",
    "\n",
    "    original_embeddings = []\n",
    "    for i, processed_original_text in enumerate(processed_original_texts):\n",
    "        original_embeddings.append([])\n",
    "        for l in range(len(processed_original_text)):\n",
    "            original_embeddings[i].append(embed([processed_original_text[l]]))\n",
    "\n",
    "    # Se hace la comparación entre los 2 textos\n",
    "    for k, processed_suspicious_text in enumerate(processed_suspicious_texts):\n",
    "        print(\"Texto sospechoso: \", suspicious_texts[k])\n",
    "        plagiarized_check = False\n",
    "        suspicious_plagiarsim_words = 0\n",
    "        suspicious_embeddings = []\n",
    "        for i in range(len(processed_suspicious_text)):\n",
    "            suspicious_embeddings.append(embed([processed_suspicious_text[i]]))\n",
    "\n",
    "        for i, processed_original_text in enumerate(processed_original_texts):\n",
    "            word_count_plagiarism = preparation(suspicious_embeddings, original_embeddings[i], processed_suspicious_text)\n",
    "            plagiarism_original_word_count = word_count_plagiarism/len(\".\".join(processed_suspicious_text).split())\n",
    "            # Checa si hay plagio\n",
    "            if word_count_plagiarism > 0:\n",
    "                print(\"\\tPlagio detectado en: \", original_texts[i])\n",
    "                print(f'\\tPorcentaje de plagio: {plagiarism_original_word_count*100:.1f}%')\n",
    "                print(\"\\t\\n\")\n",
    "                suspicious_plagiarsim_words += word_count_plagiarism\n",
    "                \n",
    "                if not plagiarized_check:\n",
    "                    system_results.append(1)\n",
    "                    plagiarized_check = True\n",
    "                \n",
    "                    \n",
    "        # No hay plagio\n",
    "        if not plagiarized_check:\n",
    "            print(\"\\tNo se encontro plagio\\n\")\n",
    "            system_results.append(0)\n",
    "\n",
    "        if suspicious_plagiarsim_words/len(\".\".join(processed_original_text).split()) > 0.15:\n",
    "            percentaje_plagiarism = suspicious_plagiarsim_words/len(\".\".join(processed_suspicious_text).split())*100\n",
    "            if percentaje_plagiarism > 100:\n",
    "                percentaje_plagiarism = 100\n",
    "            print(f'\\tHay un total de plagio en {suspicious_texts[k]} de: {percentaje_plagiarism:.1f}%')\n",
    "            print(\"\\t\\n\")\n",
    "\n",
    "    # Impresión de tablas\n",
    "    tn, fp, fn, tp = confusion_matrix(actual_results, system_results).ravel()\n",
    "    print(f'Predicted Results: {system_results}')\n",
    "    print(f'Actual Results: {actual_results}')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(actual_results, system_results, pos_label=1)\n",
    "    print(f'True Positive: {tp}')\n",
    "    print(f'False Positive: {fp}')\n",
    "    print(f'True Negative: {tn}')\n",
    "    print(f'False Negative: {fn}')\n",
    "    print(\"False Positive Rate: \", fp/(fp+tn))\n",
    "    print(\"True Positive Rate: \", tp/(tp+fn))\n",
    "    print(\"AUC:\", metrics.auc(fpr, tpr))\n",
    "\n",
    "    print_confussion_matrix(actual_results, system_results)\n",
    "    print_roc(fpr, tpr, metrics.auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision(\"original_files\", \"suspicious_files\", [0,0,0,1,1,1,0,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,1,0,1,0,0,1,0,1,0,0,0,0,1,0,1,0,0,1,0,1,0,1,0,1,0,0,0,1,1,0,0,0,0,0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
